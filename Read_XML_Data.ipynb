{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the data: \n",
    "\n",
    "* Extracted from: https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/\n",
    "* Each ID has a text document (discharge summary)\n",
    "* Each text document was annotated with the presence of one or more disease (16 types of diseases)\n",
    "* Here we focus on the presence/absence of one disease condition at a time as a binary classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For importing .xml files\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# For handeling dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re                                  # library for regular expression operations\n",
    "import string                              # for string operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import text data\n",
    "The datasets on the Harvard website come as multiple datasets in .xml format, and the text data and labels data are stored in separate files. After importing all the text data and the label data, we combine them into one single dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 1st set of text data\n",
    "file = 'data/obesity_patient_records_training.xml'\n",
    "root = ET.parse(file).getroot()\n",
    "\n",
    "text = []\n",
    "ids = []\n",
    "for i, child in enumerate(root):\n",
    "    for _, subchild in enumerate(child):\n",
    "        temp = [element.text for element in subchild]\n",
    "        text.append(temp[0])\n",
    "        ids.append(subchild.attrib[\"id\"])\n",
    "\n",
    "# Create a dataframe \n",
    "text_1 = pd.DataFrame(list(zip(ids, text)), columns=[\"id\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 2nd set of text data\n",
    "file = 'data/obesity_patient_records_training2.xml'\n",
    "root = ET.parse(file).getroot()\n",
    "\n",
    "text = []\n",
    "ids = []\n",
    "for i, child in enumerate(root):\n",
    "    for _, subchild in enumerate(child):\n",
    "        temp = [element.text for element in subchild]\n",
    "        text.append(temp[0])\n",
    "        ids.append(subchild.attrib[\"id\"])\n",
    "\n",
    "# Create a dataframe \n",
    "text_2 = pd.DataFrame(list(zip(ids, text)), columns=[\"id\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 3rd set of text data\n",
    "file = 'data/obesity_patient_records_test.xml'\n",
    "root_test = ET.parse(file).getroot()\n",
    "\n",
    "text = []\n",
    "ids = []\n",
    "for i, child in enumerate(root_test):\n",
    "    for _, subchild in enumerate(child):\n",
    "        temp = [element.text for element in subchild]\n",
    "        text.append(temp[0])\n",
    "        ids.append(subchild.attrib[\"id\"])\n",
    "\n",
    "# Create a dataframe \n",
    "text_3 = pd.DataFrame(list(zip(ids, text)), columns=[\"id\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all three text datasets\n",
    "text_all = text_1.append(text_2.append(text_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "# np.sum(text_all.duplicated('id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Import labels data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 1st set of the labels data\n",
    "file = 'data/obesity_standoff_intuitive_annotations_training.xml'\n",
    "root_truth = ET.parse(file).getroot()\n",
    "\n",
    "disease = []\n",
    "label = []\n",
    "ids = []\n",
    "for i, child in enumerate(root_truth):\n",
    "    for _, subchild in enumerate(child):       \n",
    "        for _, element in enumerate(subchild):     \n",
    "            disease.append(subchild.attrib['name'])\n",
    "            label.append(element.attrib['judgment'])\n",
    "            ids.append(element.attrib[\"id\"])\n",
    "\n",
    "# Create a dataframe \n",
    "labels_1 = pd.DataFrame(list(zip(ids, label, disease)), columns=[\"id\", \"label\", \"disease\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 2nd set of the labels data\n",
    "file = 'data/obesity_standoff_annotations_training_addendum3.xml'\n",
    "root_test = ET.parse(file).getroot()\n",
    "\n",
    "disease = []\n",
    "label = []\n",
    "ids = []\n",
    "for i, child in enumerate(root_truth):\n",
    "    for _, subchild in enumerate(child):       \n",
    "        for _, element in enumerate(subchild):     \n",
    "            disease.append(subchild.attrib['name'])\n",
    "            label.append(element.attrib['judgment'])\n",
    "            ids.append(element.attrib[\"id\"])\n",
    "\n",
    "# Create a dataframe \n",
    "labels_2 = pd.DataFrame(list(zip(ids, label, disease)), columns=[\"id\", \"label\", \"disease\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 3rd set of the labels data\n",
    "file = 'data/obesity_standoff_annotations_test_intuitive.xml'\n",
    "root_truth = ET.parse(file).getroot()\n",
    "\n",
    "disease = []\n",
    "label = []\n",
    "ids = []\n",
    "for i, child in enumerate(root_truth):\n",
    "    for _, subchild in enumerate(child):       \n",
    "        for _, element in enumerate(subchild):     \n",
    "            disease.append(subchild.attrib['name'])\n",
    "            label.append(element.attrib['judgment'])\n",
    "            ids.append(element.attrib[\"id\"])\n",
    "\n",
    "# Create a dataframe \n",
    "labels_3 = pd.DataFrame(list(zip(ids, label, disease)), columns=[\"id\", \"label\", \"disease\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the 3 labels datasets\n",
    "labels_all = labels_3.append(labels_1.append(labels_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gout                    1696\n",
       "OSA                     1689\n",
       "Gallstones              1677\n",
       "Hypertriglyceridemia    1660\n",
       "Depression              1641\n",
       "Diabetes                1623\n",
       "Asthma                  1615\n",
       "OA                      1594\n",
       "PVD                     1579\n",
       "CAD                     1562\n",
       "Obesity                 1555\n",
       "Hypertension            1508\n",
       "Venous Insufficiency    1479\n",
       "Hypercholesterolemia    1437\n",
       "GERD                    1402\n",
       "CHF                      924\n",
       "Name: disease, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One patient can have multiple diseases\n",
    "labels_all[\"disease\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1237, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data as csv files\n",
    "text_all.to_csv(\"data/text_all.csv\")\n",
    "labels_all.to_csv(\"data/labels_all.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
