{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"text-align: center\"> A Comparative Study of Text Classification of Unstructured Medical Notes with Various Levels of Class Imbalance  </div> \n",
    "### <div style=\"text-align: center\"> Using Convolutional Neural Networks and Typical Sequence Neural Networks </div>\n",
    "<div style=\"text-align: right\"> Hongxia Lu, Louis Ehwerhemuepha, Cyril Rakovski </div>\n",
    "<div style=\"text-align: right\"> Date: 8/20/2021 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* Part 1: Import Data\n",
    "* Part II: NLP Preprocessing\n",
    "* Part III: Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Import Data\n",
    "### About the data: \n",
    "\n",
    "* Extracted from: https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/\n",
    "* Each ID has a text document (discharge summary)\n",
    "* Each text document was annotated with the presence of one or more disease (16 types of diseases)\n",
    "* Here we focus on the presence/absence of one disease condition at a time as a binary classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For importing .xml files\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# For handeling dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re                                  # library for regular expression operations\n",
    "import string                              # for string operations\n",
    "\n",
    "import matplotlib.pyplot as plt            # for plotting\n",
    "\n",
    "# For text preprocessing\n",
    "import nltk                                # Natural Language Toolkit\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "from nltk.stem import PorterStemmer as ps  # module for stemming\n",
    "from nltk.tokenize import TweetTokenizer   # module for tokenizing strings\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# For building neural netwrok models\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout, Bidirectional\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "# For model evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc, plot_precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "rd_seed = 1\n",
    "np.random.seed(rd_seed)\n",
    "tf.random.set_seed(rd_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import text data\n",
    "The datasets on the Harvard website come as multiple datasets in .xml format, and the text data and labels data are stored in separate files. After importing all the text data and the label data, we combine them into one single dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 1st set of text data\n",
    "file = 'data/obesity_patient_records_training.xml'\n",
    "root = ET.parse(file).getroot()\n",
    "\n",
    "text = []\n",
    "ids = []\n",
    "for i, child in enumerate(root):\n",
    "    for _, subchild in enumerate(child):\n",
    "        temp = [element.text for element in subchild]\n",
    "        text.append(temp[0])\n",
    "        ids.append(subchild.attrib[\"id\"])\n",
    "\n",
    "# Create a dataframe \n",
    "text_1 = pd.DataFrame(list(zip(ids, text)), columns=[\"id\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 2nd set of text data\n",
    "file = 'data/obesity_patient_records_training2.xml'\n",
    "root = ET.parse(file).getroot()\n",
    "\n",
    "text = []\n",
    "ids = []\n",
    "for i, child in enumerate(root):\n",
    "    for _, subchild in enumerate(child):\n",
    "        temp = [element.text for element in subchild]\n",
    "        text.append(temp[0])\n",
    "        ids.append(subchild.attrib[\"id\"])\n",
    "\n",
    "# Create a dataframe \n",
    "text_2 = pd.DataFrame(list(zip(ids, text)), columns=[\"id\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 3rd set of text data\n",
    "file = 'data/obesity_patient_records_test.xml'\n",
    "root_test = ET.parse(file).getroot()\n",
    "\n",
    "text = []\n",
    "ids = []\n",
    "for i, child in enumerate(root_test):\n",
    "    for _, subchild in enumerate(child):\n",
    "        temp = [element.text for element in subchild]\n",
    "        text.append(temp[0])\n",
    "        ids.append(subchild.attrib[\"id\"])\n",
    "\n",
    "# Create a dataframe \n",
    "text_3 = pd.DataFrame(list(zip(ids, text)), columns=[\"id\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all three text datasets\n",
    "text_all = text_1.append(text_2.append(text_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "np.sum(text_all.duplicated('id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Import labels data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 1st set of the labels data\n",
    "file = 'data/obesity_standoff_intuitive_annotations_training.xml'\n",
    "root_truth = ET.parse(file).getroot()\n",
    "\n",
    "disease = []\n",
    "label = []\n",
    "ids = []\n",
    "for i, child in enumerate(root_truth):\n",
    "    for _, subchild in enumerate(child):       \n",
    "        for _, element in enumerate(subchild):     \n",
    "            disease.append(subchild.attrib['name'])\n",
    "            label.append(element.attrib['judgment'])\n",
    "            ids.append(element.attrib[\"id\"])\n",
    "\n",
    "# Create a dataframe \n",
    "labels_1 = pd.DataFrame(list(zip(ids, label, disease)), columns=[\"id\", \"label\", \"disease\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 2nd set of the labels data\n",
    "file = 'data/obesity_standoff_annotations_training_addendum3.xml'\n",
    "root_test = ET.parse(file).getroot()\n",
    "\n",
    "disease = []\n",
    "label = []\n",
    "ids = []\n",
    "for i, child in enumerate(root_truth):\n",
    "    for _, subchild in enumerate(child):       \n",
    "        for _, element in enumerate(subchild):     \n",
    "            disease.append(subchild.attrib['name'])\n",
    "            label.append(element.attrib['judgment'])\n",
    "            ids.append(element.attrib[\"id\"])\n",
    "\n",
    "# Create a dataframe \n",
    "labels_2 = pd.DataFrame(list(zip(ids, label, disease)), columns=[\"id\", \"label\", \"disease\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 3rd set of the labels data\n",
    "file = 'data/obesity_standoff_annotations_test_intuitive.xml'\n",
    "root_truth = ET.parse(file).getroot()\n",
    "\n",
    "disease = []\n",
    "label = []\n",
    "ids = []\n",
    "for i, child in enumerate(root_truth):\n",
    "    for _, subchild in enumerate(child):       \n",
    "        for _, element in enumerate(subchild):     \n",
    "            disease.append(subchild.attrib['name'])\n",
    "            label.append(element.attrib['judgment'])\n",
    "            ids.append(element.attrib[\"id\"])\n",
    "\n",
    "# Create a dataframe \n",
    "labels_3 = pd.DataFrame(list(zip(ids, label, disease)), columns=[\"id\", \"label\", \"disease\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the 3 labels datasets\n",
    "labels_all = labels_3.append(labels_1.append(labels_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gout                    1696\n",
       "OSA                     1689\n",
       "Gallstones              1677\n",
       "Hypertriglyceridemia    1660\n",
       "Depression              1641\n",
       "Diabetes                1623\n",
       "Asthma                  1615\n",
       "OA                      1594\n",
       "PVD                     1579\n",
       "CAD                     1562\n",
       "Obesity                 1555\n",
       "Hypertension            1508\n",
       "Venous Insufficiency    1479\n",
       "Hypercholesterolemia    1437\n",
       "GERD                    1402\n",
       "CHF                      924\n",
       "Name: disease, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One patient can have multiple diseases\n",
    "labels_all[\"disease\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24641, 3)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create a dataset from the labels data that only shows the presence of the disease of interest\n",
    "There are 16 disease conditions in the original labels data. We work with one disease at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the disease column, code the disease of interest as 1 and other disease types as 0 to indicate \n",
    "# whether this row is about this particular disease\n",
    "labels_all[\"disease\"] = [1 if x==\"Venous Insufficiency\" else 0 for x in labels_all[\"disease\"]] \n",
    "\n",
    "# In the label column, code Y as 1 and everything else as 0 to indicate whether a disease is present\n",
    "# (it may or may not be about this particular disease)\n",
    "labels_all[\"label\"] = [1 if x==\"Y\" else 0 for x in labels_all[\"label\"]] \n",
    "\n",
    "# Create a \"This_Disease\" column that indicates whether a patient has this particular disease or not\n",
    "# A patient is coded as having this disease only when (disease is 1) AND (label is 1)\n",
    "labels_all[\"This_Disease\"] = labels_all[\"disease\"] * labels_all[\"label\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that all useful info in \"disease\" and \"Label\" are combined in column \"This_Disease\", we no longer need disease and label\n",
    "labels_all = labels_all.iloc[:, [0,3]]\n",
    "# There are duplicates after removing disease and label because there are 0's in the \"disease\" column if the patient had other disease info\n",
    "cad_labels = labels_all.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Combine the text data and the labels data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the x_test and y_test sets\n",
    "df = text_all.merge(labels_all, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some text data don't have labels\n",
    "df.isnull().sum()\n",
    "\n",
    "# Remove the data that don't have labels\n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In column \"This_Disease\", if one id has both a 0 and a 1, take 1 and delete 0\n",
    "# This happened when creating column \"This_Disease\", there is always a 0 for the ids that had other disease info\n",
    "# Those disease condistions that are not of interest would result in a 0 in column \"This_Disease\".\n",
    "df[\"this_disease\"] = df.groupby([\"id\", \"text\"], squeeze=True)[\"This_Disease\"].transform(lambda x: np.max(x))\n",
    "\n",
    "# Remove the duplicates and the columns that are no longer needed\n",
    "df = df.iloc[:,[0,1,3]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1116, 3)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>this_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n490646815 | WMC | 31530471 | | 9629480 | 11/...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\\n159644670 | VH | 60656526 | | 6334749 | 11/2...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>\\n368346277 | EMH | 64927307 | | 815098 | 3/29...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                               text  this_disease\n",
       "0  1  \\n490646815 | WMC | 31530471 | | 9629480 | 11/...           0.0\n",
       "1  2  \\n159644670 | VH | 60656526 | | 6334749 | 11/2...           0.0\n",
       "2  4  \\n368346277 | EMH | 64927307 | | 815098 | 3/29...           0.0"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06541218637992832"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Disease prevalence (this also shows how balanced/imblanced the two classes are in the data)\n",
    "np.sum(df.this_disease)/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Descriptive statistics before cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words before cleaning\n",
      "Quantiles:  [ 146.  809. 1070. 1416. 4280.]\n",
      "Mean:  1157\n",
      "Standard deviation:  506\n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistics of the number of words after cleaning\n",
    "print(\"Number of words before cleaning\")\n",
    "print(\"Quantiles: \", np.round(np.quantile([len(x.split()) for x in df[\"text\"]], q = [0, 0.25, 0.5, 0.75, 1])))\n",
    "print(\"Mean: \", round(np.mean([len(x.split()) for x in df[\"text\"]])))\n",
    "print(\"Standard deviation: \", round(np.std([len(x.split()) for x in df[\"text\"]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters before cleaning\n",
      "Quantiles:  [  903.  4741.  6286.  8354. 25842.]\n",
      "Mean:  6790\n",
      "Standard deviation:  2957\n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistics of the number of characters after cleaning\n",
    "print(\"Number of characters before cleaning\")\n",
    "print(\"Quantiles: \", np.round(np.quantile([len(x) for x in df[\"text\"]], q = [0, 0.25, 0.5, 0.75, 1])))\n",
    "print(\"Mean: \", round(np.mean([len(x) for x in df[\"text\"]])))\n",
    "print(\"Standard deviation: \", round(np.std([len(x) for x in df[\"text\"]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: NLP Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Convert to lower case and remove noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all words in text column to lower case in both the train and test sets\n",
    "df['text'] = [str(x).lower() for x in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove noise\n",
    "df['text']  = [re.sub(\"(\\W|\\d+|\\n)\", \" \", elem).strip() for elem in df['text']] # remove spaces and digits and line breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuations\n",
    "def remove_punctuations(text):\n",
    "    return ' '.join(['' if (elem in string.punctuation) else elem for elem in text.split()])\n",
    "\n",
    "df['text'] = [remove_punctuations(elem) for elem in df['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Remove stop words and short words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop words are the most common words in any natural language which do not add much value in NLP modelling. They include words such as \"the\", \"is\", \"in\", \"for\", \"where\", \"when\", \"to\", \"at\".\n",
    "Based on the domain, customized stop words can also be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hanna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the stopwords from NLTK\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Import the standard English stop words list from NLTK\n",
    "stopwords_english = stopwords.words('english') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove standard English stop words\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join(['' if (elem in stopwords_english) else elem for elem in text.split()])\n",
    "\n",
    "df['text'] = [remove_stopwords(elem) for elem in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove words with a length of one or two\n",
    "def remove_short_words(text):\n",
    "    return ' '.join(['' if (len(elem) <= 2) else elem for elem in text.split()])\n",
    "\n",
    "df['text'] = [remove_short_words(elem) for elem in df['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Descriptive statistics after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words before cleaning\n",
      "Quantiles:  [  66.  414.  549.  730. 2212.]\n",
      "Mean:  591\n",
      "Standard deviation:  254\n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistics of the number of words after cleaning\n",
    "print(\"Number of words before cleaning\")\n",
    "print(\"Quantiles: \", np.round(np.quantile([len(x.split()) for x in df[\"text\"]], q = [0, 0.25, 0.5, 0.75, 1])))\n",
    "print(\"Mean: \", round(np.mean([len(x.split()) for x in df[\"text\"]])))\n",
    "print(\"Standard deviation: \", round(np.std([len(x.split()) for x in df[\"text\"]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters before cleaning\n",
      "Quantiles:  [  542.  3262.  4327.  5785. 18134.]\n",
      "Mean:  4686\n",
      "Standard deviation:  2023\n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistics of the number of characters after cleaning\n",
    "print(\"Number of characters before cleaning\")\n",
    "print(\"Quantiles: \", np.round(np.quantile([len(x) for x in df[\"text\"]], q = [0, 0.25, 0.5, 0.75, 1])))\n",
    "print(\"Mean: \", round(np.mean([len(x) for x in df[\"text\"]])))\n",
    "print(\"Standard deviation: \", round(np.std([len(x) for x in df[\"text\"]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify the label variable event\n",
    "event_categorical = to_categorical(df['this_disease'])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['text'], event_categorical, test_size=0.25, random_state=rd_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Tokenize the text data\n",
    "What the Tokenizer does is:\n",
    "* First, it creates a word-index dictionary based on word frequency, so that every word gets an integer value as the index (an integer between 1 and the maximum number of unique words in the texts. 0 is reserved for padding.)  \n",
    "* Then, it transforms each text to a sequence of integers. It basically takes each word in the text, looks it up in the word-index dictionary, and replaces it with its corresponding index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(num_words=5000) # get the frequency of all tokens and use the 5000 most common ones\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "vocab_size = len(tokenizer.word_index) + 1 # plus the reserved index 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Pad the word sequences to make each sequence the same length\n",
    "Most machine learning models (if not all) require the input data to be the same length. Text data often do not have the same length. However, we can pad the shorter text sequences with 0's to make their lengths the same. We can choose to pad the 0's at the beginning of a sequence (by setting padding=\"pre\"), or at the end (by setting padding=\"post\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 104. ,  513. ,  692. ,  874.8, 2141. ])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected quantiles of the number of words in the texts to get an idea about the length of the text sequences\n",
    "np.quantile([len(x) for x in x_train], q = [0, 0.5, 0.75, 0.9, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 104.,  385.,  513.,  692., 2141.])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile([len(x) for x in x_train], q = [0, 0.25, 0.5, 0.75, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences to make them to have the same length\n",
    "maxlen = 525 # assumes the first 522 words are the most important, and make all sequences with length 522\n",
    "x_train = pad_sequences(x_train, padding='post', maxlen=maxlen) \n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837, 525)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define a function to evaluate model performance interms of Precision, Recall, and F1 Score\n",
    "* Precision answers the question: what proportion of positive identifications was actually correct?\n",
    "* Recall answers the question: what proportion of actual positives was identified correctly?\n",
    "* F1 score, also called the F Score or the F Measure, conveys the balance between the precision and the recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to evaluate the model performance in terms of F1 score\n",
    "def evaluate(model, X, y):\n",
    "    pred = model.predict_classes(X)\n",
    "    acc = np.sum(y == pred)/len(pred)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y, pred).ravel()\n",
    "    print(\"tn  fp fn tp\")\n",
    "    print(tn, fp, fn, tp)\n",
    "\n",
    "    precision = tp/(tp + fp)\n",
    "    recall = tp/(tp + fn)\n",
    "    specificity = tn/(tn + fp)\n",
    "    f1 = (2*precision*recall)/(precision + recall)\n",
    "    print(\"\\nAccuracy: \" + str(round(acc, 3)) + \"\\nPrecision: \" + str(round(precision,3)) + \n",
    "          \"\\nRecall: \" + str(round(recall,3)) + \n",
    "          \"\\nSpecificity: \" + str(round(specificity,3)) + \"\\nF1 Score: \" + str(round(f1,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. CNN (Convolutional Neural Network) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The batch size is a hyperparameter that defines the number of samples to work through before updating the internal model parameters (weights).\n",
    "* The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of epochs and the batch size\n",
    "epochs = 20\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 525, 64)           1519680   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 518, 8)            4104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 259, 8)            0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 259, 8)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2072)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 4146      \n",
      "=================================================================\n",
      "Total params: 1,527,930\n",
      "Trainable params: 1,527,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnnmodel = Sequential()\n",
    "cnnmodel.add(layers.Embedding(input_dim=vocab_size, output_dim=64, input_length=maxlen))\n",
    "cnnmodel.add(Conv1D(8, kernel_size=8, activation=\"relu\"))\n",
    "cnnmodel.add(MaxPooling1D(pool_size=2))\n",
    "cnnmodel.add(Dropout(0.5))\n",
    "cnnmodel.add(Flatten())\n",
    "cnnmodel.add(Dense(units=2, activation='sigmoid'))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.003)\n",
    "cnnmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['AUC'])\n",
    "cnnmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 0.3340 - auc: 0.9318\n",
      "Epoch 2/20\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 0.2203 - auc: 0.9721\n",
      "Epoch 3/20\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 0.1567 - auc: 0.9902\n",
      "Epoch 4/20\n",
      "27/27 [==============================] - 2s 60ms/step - loss: 0.0791 - auc: 0.9965\n",
      "Epoch 5/20\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 0.0287 - auc: 0.9999\n",
      "Epoch 6/20\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 0.0090 - auc: 1.0000\n",
      "Epoch 7/20\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 0.0031 - auc: 1.0000\n",
      "Epoch 8/20\n",
      "27/27 [==============================] - 2s 64ms/step - loss: 0.0017 - auc: 1.0000\n",
      "Epoch 9/20\n",
      "27/27 [==============================] - 2s 62ms/step - loss: 0.0012 - auc: 1.0000 ETA: 0s - loss: 9.0037e-0\n",
      "Epoch 10/20\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 9.1238e-04 - auc: 1.0000\n",
      "Epoch 11/20\n",
      "27/27 [==============================] - 2s 65ms/step - loss: 7.2681e-04 - auc: 1.0000\n",
      "Epoch 12/20\n",
      "27/27 [==============================] - 2s 63ms/step - loss: 4.9268e-04 - auc: 1.0000\n",
      "Epoch 13/20\n",
      "27/27 [==============================] - 2s 63ms/step - loss: 4.2967e-04 - auc: 1.0000\n",
      "Epoch 14/20\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 4.4035e-04 - auc: 1.0000\n",
      "Epoch 15/20\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 3.5409e-04 - auc: 1.0000\n",
      "Epoch 16/20\n",
      "27/27 [==============================] - 2s 62ms/step - loss: 2.8441e-04 - auc: 1.0000\n",
      "Epoch 17/20\n",
      "27/27 [==============================] - 2s 67ms/step - loss: 2.6810e-04 - auc: 1.0000\n",
      "Epoch 18/20\n",
      "27/27 [==============================] - 2s 67ms/step - loss: 2.0132e-04 - auc: 1.0000: 0s - loss: 2.0727e-04 - auc: 1.00\n",
      "Epoch 19/20\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 1.9484e-04 - auc: 1.0000\n",
      "Epoch 20/20\n",
      "27/27 [==============================] - 2s 62ms/step - loss: 1.9114e-04 - auc: 1.0000: 0s - loss: 1.9268e-04 - a\n",
      "Training Accuracy: 1.0000\n",
      "Testing Accuracy:  0.9666\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "cnnmodel.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "loss, accuracy = cnnmodel.evaluate(x_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = cnnmodel.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "time_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Time: 36.179983615875244\n"
     ]
    }
   ],
   "source": [
    "print(\"Running Time:\", time_end - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_ROC: 0.8037\n",
      "AUC_PR: 0.0995\n"
     ]
    }
   ],
   "source": [
    "# Predicted probabilities on test data\n",
    "y_pred = cnnmodel.predict(x_test)\n",
    "\n",
    "# AUC-ROC (area under the Receiver Operating Characteristic curve)\n",
    "auc_roc = round(roc_auc_score(y_test[:,1], y_pred[:,1]),4)\n",
    "\n",
    "# AUC-PR (area under the Precision Recall Curve)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test[:,1], y_pred[:,1])\n",
    "auc_precision_recall = round(auc(recall, precision),4)\n",
    "\n",
    "print(\"AUC_ROC: \" + str(auc_roc))\n",
    "print(\"AUC_PR: \" + str(auc_precision_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn  fp fn tp\n",
      "269 0 10 0\n",
      "\n",
      "Accuracy: 0.964\n",
      "Precision: nan\n",
      "Recall: 0.0\n",
      "Specificity: 1.0\n",
      "F1 Score: nan\n"
     ]
    }
   ],
   "source": [
    "# Accuracy and F1 Score\n",
    "evaluate(cnnmodel, x_test, y_test[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. RNN (Recurrent Neural Network) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN model\n",
    "rnnmodel = Sequential()\n",
    "rnnmodel.add(layers.Embedding(input_dim=vocab_size, output_dim=64, input_length=maxlen))\n",
    "rnnmodel.add(layers.SimpleRNN(units=8)) \n",
    "rnnmodel.add(Dropout(0.5))\n",
    "rnnmodel.add(layers.Dense(2, activation='sigmoid'))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.003)\n",
    "rnnmodel.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['AUC'])\n",
    "rnnmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "rnnmodel.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "loss, accuracy = rnnmodel.evaluate(x_train, y_train)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = rnnmodel.evaluate(x_test, y_test)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "time_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running Time:\", time_end - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted probabilities on test data\n",
    "y_pred = rnnmodel.predict(x_test)\n",
    "\n",
    "# AUC-ROC (area under the Receiver Operating Characteristic curve)\n",
    "auc_roc = round(roc_auc_score(y_test[:,1], y_pred[:,1]),4)\n",
    "\n",
    "# AUC-PR (area under the Precision Recall Curve)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test[:,1], y_pred[:,1])\n",
    "auc_precision_recall = round(auc(recall, precision),4)\n",
    "\n",
    "print(\"AUC_ROC: \" + str(auc_roc))\n",
    "print(\"AUC_PR: \" + str(auc_precision_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Accuracy and F1 Score\n",
    "evaluate(rnnmodel, x_test, y_test[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. GRU (Gated Recurrent Unit) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU model\n",
    "grumodel = Sequential()\n",
    "grumodel.add(layers.Embedding(input_dim=vocab_size, output_dim=64, input_length=maxlen))\n",
    "grumodel.add(layers.GRU(units=8)) \n",
    "grumodel.add(Dropout(0.5))\n",
    "grumodel.add(layers.Dense(2, activation='sigmoid'))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.003)\n",
    "grumodel.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['AUC'])\n",
    "grumodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "grumodel.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "loss, accuracy = grumodel.evaluate(x_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = grumodel.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "time_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running Time:\", time_end - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted probabilities on test data\n",
    "y_pred = grumodel.predict(x_test)\n",
    "\n",
    "# AUC-ROC (area under the Receiver Operating Characteristic curve)\n",
    "auc_roc = round(roc_auc_score(y_test[:,1], y_pred[:,1]),4)\n",
    "\n",
    "# AUC-PR (area under the Precision Recall Curve)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test[:,1], y_pred[:,1])\n",
    "auc_precision_recall = round(auc(recall, precision),4)\n",
    "\n",
    "print(\"AUC_ROC: \" + str(auc_roc))\n",
    "print(\"AUC_PR: \" + str(auc_precision_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy and F1 Score\n",
    "evaluate(grumodel, x_test, y_test[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. LSTM (Long Short Term Memory) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(layers.Embedding(input_dim=vocab_size, output_dim=64, input_length=maxlen))\n",
    "lstm_model.add(layers.LSTM(units=8)) \n",
    "lstm_model.add(Dropout(0.5))\n",
    "lstm_model.add(layers.Dense(2, activation='sigmoid'))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.003)\n",
    "lstm_model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "lstm_model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "loss, accuracy = lstm_model.evaluate(x_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = lstm_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "time_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running Time:\", time_end - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted probabilities on test data\n",
    "y_pred = lstm_model.predict(x_test)\n",
    "\n",
    "# AUC-ROC (area under the Receiver Operating Characteristic curve)\n",
    "auc_roc = round(roc_auc_score(y_test[:,1], y_pred[:,1]),4)\n",
    "\n",
    "# AUC-PR (area under the Precision Recall Curve)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test[:,1], y_pred[:,1])\n",
    "auc_precision_recall = round(auc(recall, precision),4)\n",
    "\n",
    "print(\"AUC_ROC: \" + str(auc_roc))\n",
    "print(\"AUC_PR: \" + str(auc_precision_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy and F1 Score\n",
    "evaluate(lstm_model, x_test, y_test[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-Directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi-directional LSTM model\n",
    "bi_lstm_model = Sequential()\n",
    "bi_lstm_model.add(layers.Embedding(input_dim=vocab_size, output_dim=64, input_length=maxlen))\n",
    "bi_lstm_model.add(layers.Bidirectional(layers.LSTM(8)))\n",
    "bi_lstm_model.add(Dropout(0.5))\n",
    "bi_lstm_model.add(layers.Dense(2, activation='sigmoid'))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.003)\n",
    "bi_lstm_model.compile(optimizer=opt,\n",
    "              loss=losses.categorical_crossentropy,\n",
    "              metrics=['AUC'])\n",
    "bi_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "bi_lstm_model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "loss, accuracy = bi_lstm_model.evaluate(x_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = bi_lstm_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "time_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running Time:\", time_end - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted probabilities on test data\n",
    "y_pred = bi_lstm_model.predict(x_test)\n",
    "\n",
    "# AUC-ROC (area under the Receiver Operating Characteristic curve)\n",
    "auc_roc = round(roc_auc_score(y_test[:,1], y_pred[:,1]),4)\n",
    "\n",
    "# AUC-PR (area under the Precision Recall Curve)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test[:,1], y_pred[:,1])\n",
    "auc_precision_recall = round(auc(recall, precision),4)\n",
    "\n",
    "print(\"AUC_ROC: \" + str(auc_roc))\n",
    "print(\"AUC_PR: \" + str(auc_precision_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy and F1 Score\n",
    "evaluate(bi_lstm_model, x_test, y_test[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
